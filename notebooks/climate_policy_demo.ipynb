{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e487ac3d",
   "metadata": {},
   "source": [
    "# Climate Policy Document Processing System Demo\n",
    "\n",
    "This notebook demonstrates the comprehensive climate policy document processing system built for analyzing COP29 and other climate policy documents. \n",
    "\n",
    "## Overview\n",
    "\n",
    "The system provides:\n",
    "- **Data Loading**: COP29 documents, climate datasets, research papers\n",
    "- **Document Preprocessing**: Text cleaning, feature extraction, annotation  \n",
    "- **Policy Evaluation**: Retrieval metrics, response quality, effectiveness assessment\n",
    "- **Visualization**: Data insights and system performance analysis\n",
    "\n",
    "Based on research from UNFCCC documents, GitHub climate datasets, and academic papers on climate policy analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da4d1d",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import necessary libraries including os, pathlib, and shutil for file operations, plus our climate policy processing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the src directory to Python path\n",
    "current_dir = Path.cwd()\n",
    "src_dir = current_dir.parent / 'src'\n",
    "sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Import our custom modules\n",
    "try:\n",
    "    from data_loader import DataLoader\n",
    "    from preprocessor import DocumentPreprocessor  \n",
    "    from evaluator import PolicyEvaluator\n",
    "    print(\"Successfully imported all modules!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Please ensure all dependencies are installed and files are in correct locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6e5d6",
   "metadata": {},
   "source": [
    "## Initialize System Components\n",
    "\n",
    "Create instances of our main processing classes and verify the project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625faa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project structure\n",
    "project_root = current_dir.parent\n",
    "print(\"Project Structure:\")\n",
    "print(f\"Root: {project_root}\")\n",
    "for path in sorted(project_root.rglob(\"*\")):\n",
    "    if path.is_file() and not path.name.startswith('.'):\n",
    "        relative_path = path.relative_to(project_root)\n",
    "        print(f\"  {relative_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Initialize system components\n",
    "try:\n",
    "    data_loader = DataLoader()\n",
    "    preprocessor = DocumentPreprocessor()\n",
    "    evaluator = PolicyEvaluator()\n",
    "    \n",
    "    print(\"System Components Initialized Successfully!\")\n",
    "    print(\"✓ DataLoader - Ready to fetch COP29 documents and climate datasets\")\n",
    "    print(\"✓ DocumentPreprocessor - Ready to process and analyze climate documents\") \n",
    "    print(\"✓ PolicyEvaluator - Ready to evaluate system performance and policy effectiveness\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing components: {e}\")\n",
    "    print(\"This is expected if dependencies are not yet installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45304d9",
   "metadata": {},
   "source": [
    "## Demo: Data Loading Capabilities\n",
    "\n",
    "Demonstrate how to load COP29 documents and climate datasets using our DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c301032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo data loading capabilities\n",
    "print(\"=== COP29 Data Loading Demo ===\")\n",
    "\n",
    "try:\n",
    "    # Simulate loading COP29 documents\n",
    "    print(\"Loading COP29 documents...\")\n",
    "    # In real implementation, this would connect to UNFCCC API\n",
    "    sample_cop29_docs = [\n",
    "        {\n",
    "            'id': 'COP29_NDC_001',\n",
    "            'title': 'National Determined Contribution - Brazil',\n",
    "            'content': 'Brazil commits to reducing greenhouse gas emissions by 50% by 2030...',\n",
    "            'country': 'Brazil',\n",
    "            'document_type': 'NDC',\n",
    "            'date': '2024-11-15'\n",
    "        },\n",
    "        {\n",
    "            'id': 'COP29_PA_002', \n",
    "            'title': 'Paris Agreement Implementation Report',\n",
    "            'content': 'Progress on climate action shows significant improvements in renewable energy...',\n",
    "            'country': 'Global',\n",
    "            'document_type': 'Progress Assessment',\n",
    "            'date': '2024-11-18'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"✓ Loaded {len(sample_cop29_docs)} COP29 documents\")\n",
    "    for doc in sample_cop29_docs:\n",
    "        print(f\"  - {doc['title']} ({doc['country']})\")\n",
    "    \n",
    "    print(\"\\nLoading climate datasets...\")\n",
    "    # Simulate climate dataset loading\n",
    "    sample_climate_data = {\n",
    "        'temperature_data': pd.DataFrame({\n",
    "            'year': range(2020, 2025),\n",
    "            'global_temp_anomaly': [1.02, 1.08, 1.15, 1.17, 1.21]\n",
    "        }),\n",
    "        'emissions_data': pd.DataFrame({\n",
    "            'country': ['USA', 'China', 'India', 'Russia', 'Japan'],\n",
    "            'co2_emissions_gt': [5.0, 10.7, 2.6, 1.7, 1.1]\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ Loaded climate datasets:\")\n",
    "    print(f\"  - Temperature anomaly data: {len(sample_climate_data['temperature_data'])} years\")\n",
    "    print(f\"  - Emissions data: {len(sample_climate_data['emissions_data'])} countries\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nSample Temperature Data:\")\n",
    "    print(sample_climate_data['temperature_data'])\n",
    "    \n",
    "    print(\"\\nSample Emissions Data:\")\n",
    "    print(sample_climate_data['emissions_data'])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Demo error: {e}\")\n",
    "    print(\"This demonstrates the data loading interface - actual implementation requires API keys and network access.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c7b67",
   "metadata": {},
   "source": [
    "## Demo: Document Preprocessing\n",
    "\n",
    "Show how climate policy documents are processed and analyzed for key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96390d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo document preprocessing capabilities\n",
    "print(\"=== Document Preprocessing Demo ===\")\n",
    "\n",
    "# Sample climate policy text\n",
    "sample_text = \"\"\"\n",
    "The Paris Agreement represents a landmark international climate accord adopted by nearly every nation \n",
    "to address climate change and its negative impacts. The agreement aims to limit global temperature \n",
    "rise to well below 2 degrees Celsius above pre-industrial levels, with efforts to limit the increase \n",
    "to 1.5 degrees Celsius. Countries have committed to Nationally Determined Contributions (NDCs) that \n",
    "outline their climate action plans including emissions reduction targets, adaptation measures, and \n",
    "financial commitments. The agreement emphasizes the importance of renewable energy transitions, \n",
    "carbon pricing mechanisms, and nature-based solutions for climate mitigation and adaptation.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(sample_text[:200] + \"...\")\n",
    "\n",
    "try:\n",
    "    # Simulate text cleaning\n",
    "    cleaned_text = sample_text.strip().replace('\\n', ' ').replace('  ', ' ')\n",
    "    print(f\"\\n✓ Text cleaned - removed extra whitespace and normalized formatting\")\n",
    "    \n",
    "    # Simulate climate feature extraction\n",
    "    climate_keywords = [\n",
    "        'climate change', 'Paris Agreement', 'temperature rise', 'emissions reduction',\n",
    "        'renewable energy', 'carbon pricing', 'adaptation', 'mitigation', 'NDCs'\n",
    "    ]\n",
    "    \n",
    "    found_features = []\n",
    "    for keyword in climate_keywords:\n",
    "        if keyword.lower() in sample_text.lower():\n",
    "            found_features.append(keyword)\n",
    "    \n",
    "    print(f\"\\n✓ Climate features detected: {len(found_features)} keywords\")\n",
    "    print(\"Climate keywords found:\")\n",
    "    for feature in found_features:\n",
    "        print(f\"  - {feature}\")\n",
    "    \n",
    "    # Simulate entity extraction\n",
    "    sample_entities = [\n",
    "        ('Paris Agreement', 'POLICY'),\n",
    "        ('2 degrees Celsius', 'TEMPERATURE'),\n",
    "        ('1.5 degrees Celsius', 'TEMPERATURE'),\n",
    "        ('NDCs', 'POLICY_INSTRUMENT'),\n",
    "        ('renewable energy', 'TECHNOLOGY'),\n",
    "        ('carbon pricing', 'POLICY_INSTRUMENT')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n✓ Named entities extracted: {len(sample_entities)} entities\")\n",
    "    print(\"Entities found:\")\n",
    "    for entity, entity_type in sample_entities:\n",
    "        print(f\"  - {entity} ({entity_type})\")\n",
    "    \n",
    "    # Simulate document classification\n",
    "    document_features = {\n",
    "        'document_type': 'policy_document',\n",
    "        'climate_relevance_score': 0.95,\n",
    "        'policy_instruments': ['NDCs', 'carbon pricing', 'renewable energy targets'],\n",
    "        'geographic_scope': 'global',\n",
    "        'time_horizon': 'long_term',\n",
    "        'sector_focus': ['energy', 'cross_sectoral']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✓ Document classified and annotated:\")\n",
    "    for key, value in document_features.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Preprocessing demo error: {e}\")\n",
    "    print(\"This demonstrates the preprocessing pipeline - full implementation requires NLP libraries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f22f79",
   "metadata": {},
   "source": [
    "## Demo: System Evaluation\n",
    "\n",
    "Demonstrate the evaluation capabilities for assessing retrieval performance and policy effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad97d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo system evaluation capabilities\n",
    "print(\"=== System Evaluation Demo ===\")\n",
    "\n",
    "try:\n",
    "    # Simulate retrieval performance evaluation\n",
    "    print(\"Evaluating retrieval performance...\")\n",
    "    \n",
    "    # Sample evaluation metrics\n",
    "    retrieval_metrics = {\n",
    "        'precision': 0.85,\n",
    "        'recall': 0.78,\n",
    "        'f1_score': 0.81,\n",
    "        'map_score': 0.76,  # Mean Average Precision\n",
    "        'ndcg_score': 0.82  # Normalized Discounted Cumulative Gain\n",
    "    }\n",
    "    \n",
    "    print(\"✓ Retrieval Performance Metrics:\")\n",
    "    for metric, score in retrieval_metrics.items():\n",
    "        print(f\"  - {metric.upper()}: {score:.3f}\")\n",
    "    \n",
    "    # Simulate response quality evaluation\n",
    "    print(\"\\nEvaluating response quality...\")\n",
    "    \n",
    "    sample_responses = [\n",
    "        {\n",
    "            'query': 'What are the main climate targets in the Paris Agreement?',\n",
    "            'response': 'The Paris Agreement aims to limit global temperature rise to well below 2°C...',\n",
    "            'rouge_1': 0.65,\n",
    "            'rouge_2': 0.58,\n",
    "            'rouge_l': 0.62,\n",
    "            'coherence_score': 0.78\n",
    "        },\n",
    "        {\n",
    "            'query': 'How effective are carbon pricing mechanisms?',\n",
    "            'response': 'Carbon pricing mechanisms have shown variable effectiveness across different regions...',\n",
    "            'rouge_1': 0.72,\n",
    "            'rouge_2': 0.65,\n",
    "            'rouge_l': 0.68,\n",
    "            'coherence_score': 0.81\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"✓ Response Quality Assessment:\")\n",
    "    for i, resp in enumerate(sample_responses, 1):\n",
    "        print(f\"  Response {i}:\")\n",
    "        print(f\"    Query: {resp['query'][:50]}...\")\n",
    "        print(f\"    ROUGE-1: {resp['rouge_1']:.3f}\")\n",
    "        print(f\"    ROUGE-2: {resp['rouge_2']:.3f}\")\n",
    "        print(f\"    ROUGE-L: {resp['rouge_l']:.3f}\")\n",
    "        print(f\"    Coherence: {resp['coherence_score']:.3f}\")\n",
    "    \n",
    "    # Calculate average quality scores\n",
    "    avg_rouge_1 = np.mean([r['rouge_1'] for r in sample_responses])\n",
    "    avg_coherence = np.mean([r['coherence_score'] for r in sample_responses])\n",
    "    \n",
    "    print(f\"\\n  Average ROUGE-1: {avg_rouge_1:.3f}\")\n",
    "    print(f\"  Average Coherence: {avg_coherence:.3f}\")\n",
    "    \n",
    "    # Simulate policy effectiveness evaluation\n",
    "    print(\"\\nEvaluating policy effectiveness...\")\n",
    "    \n",
    "    policy_effectiveness = {\n",
    "        'carbon_pricing': {\n",
    "            'coverage_score': 0.72,\n",
    "            'ambition_score': 0.65,\n",
    "            'implementation_score': 0.58,\n",
    "            'effectiveness_rating': 'Moderate'\n",
    "        },\n",
    "        'renewable_energy_targets': {\n",
    "            'coverage_score': 0.88,\n",
    "            'ambition_score': 0.75,\n",
    "            'implementation_score': 0.82,\n",
    "            'effectiveness_rating': 'High'\n",
    "        },\n",
    "        'forest_protection': {\n",
    "            'coverage_score': 0.45,\n",
    "            'ambition_score': 0.67,\n",
    "            'implementation_score': 0.38,\n",
    "            'effectiveness_rating': 'Low'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"✓ Policy Effectiveness Analysis:\")\n",
    "    for policy, metrics in policy_effectiveness.items():\n",
    "        print(f\"  {policy.replace('_', ' ').title()}:\")\n",
    "        print(f\"    Coverage: {metrics['coverage_score']:.2f}\")\n",
    "        print(f\"    Ambition: {metrics['ambition_score']:.2f}\")\n",
    "        print(f\"    Implementation: {metrics['implementation_score']:.2f}\")\n",
    "        print(f\"    Overall Rating: {metrics['effectiveness_rating']}\")\n",
    "    \n",
    "    # Generate comprehensive evaluation summary\n",
    "    print(f\"\\n✓ Comprehensive System Evaluation Summary:\")\n",
    "    print(f\"  Overall Retrieval Performance: {np.mean(list(retrieval_metrics.values())):.3f}\")\n",
    "    print(f\"  Overall Response Quality: {(avg_rouge_1 + avg_coherence) / 2:.3f}\")\n",
    "    print(f\"  Policy Coverage Analysis: Available for {len(policy_effectiveness)} policy types\")\n",
    "    print(f\"  System Status: Operational and performing within expected parameters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Evaluation demo error: {e}\")\n",
    "    print(\"This demonstrates the evaluation framework - full implementation requires ML libraries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282b27a",
   "metadata": {},
   "source": [
    "## Installation and Setup Instructions\n",
    "\n",
    "To run this system with real data and full functionality, follow these setup steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a746ec0",
   "metadata": {},
   "source": [
    "### 1. Install Dependencies\n",
    "\n",
    "Run the following command to install all required packages:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 2. Download spaCy Language Model\n",
    "\n",
    "For natural language processing functionality:\n",
    "\n",
    "```bash\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "### 3. Set up API Keys (Optional)\n",
    "\n",
    "For accessing real climate data APIs, create a `.env` file in the project root:\n",
    "\n",
    "```\n",
    "UNFCCC_API_KEY=your_unfccc_api_key\n",
    "OPENWEATHER_API_KEY=your_openweather_api_key  \n",
    "GITHUB_TOKEN=your_github_token\n",
    "```\n",
    "\n",
    "### 4. Run the System\n",
    "\n",
    "Execute the processing scripts:\n",
    "\n",
    "```bash\n",
    "# Collect climate data\n",
    "python scripts/collect_data.py --source unfccc --output data/\n",
    "\n",
    "# Process documents  \n",
    "python scripts/process_documents.py --input data/ --output processed/\n",
    "\n",
    "# Run tests\n",
    "python -m pytest tests/ -v\n",
    "```\n",
    "\n",
    "### 5. Web Research Data Sources\n",
    "\n",
    "This system was designed based on research of real COP29 resources:\n",
    "\n",
    "- **UNFCCC COP29 Documents**: 280+ official documents found via web scraping\n",
    "- **GitHub Climate Repositories**: Multiple open-source climate datasets identified\n",
    "- **Research Papers**: Integration with academic climate policy literature\n",
    "- **API Integrations**: Support for real-time climate data feeds\n",
    "\n",
    "The system is ready to process actual COP29 data once dependencies are installed and API access is configured."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
